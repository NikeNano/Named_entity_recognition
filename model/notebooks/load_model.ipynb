{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gs://named_entity_recognition/ml_engine/export/exporter/1547053937/variables/variables\n"
     ]
    }
   ],
   "source": [
    "export_dir = r\"gs://named_entity_recognition/ml_engine/export/exporter/1547053937/\"\n",
    "predict_fn = predictor.from_saved_model(export_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_lowercase\n",
    "MAPPING = {a:index for index,a in enumerate(ascii_lowercase + ascii_lowercase.upper())}\n",
    "class PadList(list):\n",
    "    \"\"\" The super padding list used for padding data\n",
    "    \"\"\"\n",
    "    def inner_pad(self, pad_length, pad_value=0):\n",
    "        \"\"\"Do inner padding of the list\n",
    "        \n",
    "        Paramters:\n",
    "            padd_length -- How long should the list be\n",
    "            padd_value -- What value should be used for the padding\n",
    "        \n",
    "        Return:\n",
    "            self -- the list \n",
    "        \"\"\"\n",
    "        nbr_pad = pad_length - len(self)\n",
    "        if nbr_pad>0:\n",
    "            self = self + [pad_value] * nbr_pad\n",
    "        else:\n",
    "            self=self[:pad_length]\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def outer_pad(self,padded_list_length,pad_length,pad_value=0):\n",
    "        \"\"\"\n",
    "        Out padding of a list e.g append a list to a list. \n",
    "        Args:\n",
    "            padded_list_length -- how long should the appended list be\n",
    "            pad_lenght -- how long should the list be e.g how much should we append\n",
    "            padd_value -- What should the appended list have as values\n",
    "        \"\"\"\n",
    "        nbr_pad = pad_length-len(self)\n",
    "        if nbr_pad > 0:\n",
    "            for _ in range(nbr_pad):\n",
    "                self.append([pad_value] * padded_list_length)\n",
    "        else:\n",
    "            self = self[:pad_length]\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chars(text=None):\n",
    "    #text = element[\"text\"]\n",
    "    UNKONWN=52\n",
    "    PADD_VALUE_CHAR=UNKONWN+1\n",
    "    MAX_WORD_LEN=15\n",
    "    MAX_SENTENCE_LEN=25\n",
    "    mapped=PadList()\n",
    "    for word in text.split(\" \"):\n",
    "        tmp_mapped=PadList()\n",
    "        for char in word:\n",
    "            try:\n",
    "                tmp_mapped.append(MAPPING[char.strip()])\n",
    "            except:\n",
    "                tmp_mapped.append(UNKONWN)\n",
    "        tmp_mapped=tmp_mapped.inner_pad(MAX_WORD_LEN,PADD_VALUE_CHAR)\n",
    "        mapped.append(tmp_mapped)\n",
    "    mapped = mapped.outer_pad(padded_list_length=MAX_WORD_LEN,pad_length=MAX_SENTENCE_LEN,pad_value=PADD_VALUE_CHAR)\n",
    "    return mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_lengths(text=None):\n",
    "    MAX_WORD_LEN=15\n",
    "    MAX_SENTENCE_LEN=25\n",
    "    word_lengths  = PadList([len(word) if len(word)<MAX_WORD_LEN else MAX_WORD_LEN for word in text.split()])\n",
    "    return word_lengths.inner_pad(MAX_SENTENCE_LEN,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gs://named_entity_recognition/ml_engine/export/exporter/1547053937/variables/variables\n"
     ]
    }
   ],
   "source": [
    "predictor_fn = tf.contrib.predictor.from_saved_model(\n",
    "                export_dir=export_dir,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'chars': <tf.Tensor 'ParseExample/ParseExample:0' shape=(?, 25, 15) dtype=int64>,\n",
       " u'chars_in_word': <tf.Tensor 'ParseExample/ParseExample:1' shape=(?, 25) dtype=int64>,\n",
       " u'sentence_length': <tf.Tensor 'ParseExample/ParseExample:2' shape=(?,) dtype=int64>,\n",
       " u'text': <tf.Tensor 'ParseExample/ParseExample:3' shape=(?,) dtype=string>}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_fn.feed_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\" Mr Niklas will move to London\"\n",
    "data = {\n",
    "        'text': [text],\n",
    "        \"chars\" : [get_chars(text)],\n",
    "        'sentence_length':[len((text.strip().split(\" \")))],\n",
    "        'chars_in_word': [word_lengths(text)],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'pred_ids': array([[0, 3, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0]], dtype=int32),\n",
       " u'tags': array([['O', 'B-PER', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O',\n",
       "         'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "         'O']], dtype=object)}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = predictor_fn(data)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'pred_ids': array([[0, 3, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0]], dtype=int32), u'tags': array([['O', 'B-PER', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O',\n",
      "        'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
      "        'O']], dtype=object)}\n"
     ]
    }
   ],
   "source": [
    "predictions = predict_fn(data)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "It seams like it has a hard time with short sentences. Longer sentences are much better!\n",
    "Lets see what happens if i let the model run longer. Set up a propper long training run tomorrow! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
