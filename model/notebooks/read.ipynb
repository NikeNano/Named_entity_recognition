{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow_transform.tf_metadata import dataset_metadata, metadata_io,dataset_schema \n",
    "from tensorflow_transform.beam.tft_beam_io import transform_fn_io\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Niklas/Documents/Named_entity_recognition/model/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAVE TO RE RUN ALL! AND CLEAR FOLDERS\n",
    "\n",
    "https://guillaumegenthial.github.io/sequence-tagging-with-tensorflow.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_metadata = metadata_io.read_metadata(\n",
    "    os.path.join(\n",
    "      \"gs://named_entity_recognition/beam/\", transform_fn_io.TRANSFORMED_METADATA_DIR\n",
    "      )\n",
    "    )\n",
    "transformed_feature_spec = transformed_metadata.schema.as_feature_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'chars': FixedLenFeature(shape=[30, 10], dtype=tf.int64, default_value=None),\n",
       " u'chars_in_word': FixedLenFeature(shape=[30], dtype=tf.int64, default_value=None),\n",
       " u'id': FixedLenFeature(shape=[], dtype=tf.float32, default_value=None),\n",
       " u'label': FixedLenFeature(shape=[], dtype=tf.string, default_value=None),\n",
       " u'label_length': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None),\n",
       " u'labels': FixedLenFeature(shape=[30], dtype=tf.int64, default_value=None),\n",
       " u'sentence_length': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None),\n",
       " u'text': FixedLenFeature(shape=[], dtype=tf.string, default_value=None),\n",
       " u'word_representation': VarLenFeature(dtype=tf.int64)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_feature_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_from_tfrecord(example_proto):\n",
    "    features = tf.parse_example([example_proto], features=transformed_feature_spec)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.TFRecordDataset(\"gs://named_entity_recognition/beam/TEST-00000-of-00001\").map(_read_from_tfrecord).shuffle(10).batch(2).make_one_shot_iterator()\n",
    "for x in ds:\n",
    "    output_list.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[2 8 8 0 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]]\n",
      "\n",
      " [[2 8 8 0 1 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]]], shape=(2, 1, 30), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[2 8 8 0 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]]\n",
      "\n",
      " [[2 8 8 0 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]]], shape=(2, 1, 30), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[2 8 8 0 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]]\n",
      "\n",
      " [[2 8 8 0 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]]], shape=(2, 1, 30), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[2 8 8 0 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]]\n",
      "\n",
      " [[2 8 8 0 1 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]]], shape=(2, 1, 30), dtype=int64)\n",
      "tf.Tensor([[[2 8 8 0 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]]], shape=(1, 1, 30), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for x in output_list:\n",
    "    print(x[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_lowercase\n",
    "MAPPING = {a:index for index,a in enumerate(ascii_lowercase + ascii_lowercase.upper())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'word_representation',\n",
       " u'text',\n",
       " u'chars',\n",
       " u'labels',\n",
       " u'label',\n",
       " u'label_length',\n",
       " u'sentence_length',\n",
       " u'id',\n",
       " u'chars_in_word']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[2 8 8 0 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]]\n",
      "\n",
      " [[2 8 8 0 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]]], shape=(2, 1, 30), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[4]\n",
      " [4]], shape=(2, 1), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(x['labels'])\n",
    "print(x['sentence_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCE_LEN=30\n",
    "WORD_LEN=10\n",
    "BATCH_SIZE=2\n",
    "CHAR_SIZE=54\n",
    "EMBED_DIM_CHAR=int(CHAR_SIZE**(1/4))*8\n",
    "DEFAULT_WORD_VALUE =0\n",
    "VOCAB_SIZE=1e4\n",
    "EMBED_DIM_WORD=int(VOCAB_SIZE**(1/4))*8\n",
    "input_char = tf.reshape(x[\"chars\"],[BATCH_SIZE,SENTENCE_LEN,WORD_LEN])\n",
    "char_embedding = tf.contrib.layers.embed_sequence(\n",
    "    input_char, vocab_size=CHAR_SIZE, embed_dim=EMBED_DIM_CHAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No padding needed now :) \n",
    "input_word = tf.sparse_to_dense(x[\"word_representation\"].indices,[BATCH_SIZE,1,SENTENCE_LEN],\n",
    "                           x[\"word_representation\"].values,default_value=DEFAULT_WORD_VALUE\n",
    "                          )\n",
    "input_word = tf.reshape(input_word,[BATCH_SIZE,SENTENCE_LEN])\n",
    "word_embedding = tf.contrib.layers.embed_sequence(\n",
    "    input_word, vocab_size=VOCAB_SIZE, embed_dim=EMBED_DIM_WORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=821, shape=(2, 1, 30), dtype=int64, numpy=\n",
       "array([[[2, 8, 8, 0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "         8, 8, 8, 8, 8, 8, 8, 8, 8]],\n",
       "\n",
       "       [[2, 8, 8, 0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "         8, 8, 8, 8, 8, 8, 8, 8, 8]]])>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=821, shape=(2, 1, 30), dtype=int64, numpy=\n",
       "array([[[2, 8, 8, 0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "         8, 8, 8, 8, 8, 8, 8, 8, 8]],\n",
       "\n",
       "       [[2, 8, 8, 0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "         8, 8, 8, 8, 8, 8, 8, 8, 8]]])>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1985, shape=(2, 30), dtype=int64, numpy=\n",
       "array([[14,  0,  1, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [17,  0,  1, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 2 30], shape=(2,), dtype=int32)\n",
      "tf.Tensor([ 2 30 80], shape=(3,), dtype=int32)\n",
      "tf.Tensor([ 2 30 10 16], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes \n",
    "print(tf.shape(input_word))\n",
    "print(tf.shape(word_embedding))\n",
    "print(tf.shape(char_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.shape(char_embedding)\n",
    "char_embeddings = tf.reshape(char_embedding, shape=[-1, s[-2], s[-1]])\n",
    "word_lengths = tf.reshape(x['chars_in_word'],[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_HIDDEN_SIZE=10\n",
    "# 3. bi lstm on chars\n",
    "cell_fw = tf.contrib.rnn.LSTMCell(CHAR_HIDDEN_SIZE, state_is_tuple=True)\n",
    "cell_bw = tf.contrib.rnn.LSTMCell(CHAR_HIDDEN_SIZE, state_is_tuple=True)\n",
    "\n",
    "_, ((_, output_fw), (_, output_bw)) = tf.nn.bidirectional_dynamic_rnn(cell_fw,\n",
    "    cell_bw, char_embeddings, sequence_length=word_lengths,\n",
    "    dtype=tf.float32)\n",
    "#shape = (batch x sentence, 2 x char_hidden_size)\n",
    "output = tf.concat([output_fw, output_bw], axis=-1)\n",
    "\n",
    "# shape = (batch, sentence, 2 x char_hidden_size)\n",
    "char_rep = tf.reshape(output, shape=[-1, s[1], 2*CHAR_HIDDEN_SIZE])\n",
    "\n",
    "# shape = (batch, sentence, 2 x char_hidden_size + word_vector_size)\n",
    "word_embeddings = tf.concat([word_embedding, char_rep], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2022, shape=(60,), dtype=int64, numpy=\n",
       "array([5, 5, 2, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 7, 5, 2, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_words = tf.shape(char_embeddings)[1]\n",
    "dim_chars = tf.shape(char_embeddings)[2]\n",
    "flat = tf.reshape(char_embeddings, [-1, dim_words,EMBED_DIM_CHAR])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.11493748 -0.18082732 -0.08957429 ... -0.2770458   0.02863061\n",
      "   -0.2883652 ]\n",
      "  [-0.03224564 -0.24759862 -0.0166758  ... -0.0525489   0.00500345\n",
      "   -0.240506  ]\n",
      "  [-0.16266385 -0.26379517  0.27315307 ... -0.05415455 -0.28551635\n",
      "   -0.14136389]\n",
      "  ...\n",
      "  [ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]\n",
      "  [ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]\n",
      "  [ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]]\n",
      "\n",
      " [[ 0.14575443  0.1375423  -0.28184757 ...  0.28168172 -0.23467132\n",
      "    0.03394204]\n",
      "  [-0.16266385 -0.26379517  0.27315307 ... -0.05415455 -0.28551635\n",
      "   -0.14136389]\n",
      "  [ 0.16457126 -0.1254763  -0.28730524 ...  0.06018466 -0.17130196\n",
      "   -0.03348517]\n",
      "  ...\n",
      "  [ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]\n",
      "  [ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]\n",
      "  [ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]]\n",
      "\n",
      " [[ 0.24770612 -0.05870186 -0.11032484 ... -0.14906687  0.01738882\n",
      "   -0.2531978 ]\n",
      "  [-0.06661837  0.1742154   0.03891653 ... -0.0500613   0.1951547\n",
      "    0.27972376]\n",
      "  [ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]\n",
      "  ...\n",
      "  [ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]\n",
      "  [ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]\n",
      "  [ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]\n",
      "  [ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]\n",
      "  [ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]\n",
      "  ...\n",
      "  [ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]\n",
      "  [ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]\n",
      "  [ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]]\n",
      "\n",
      " [[ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]\n",
      "  [ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]\n",
      "  [ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]\n",
      "  ...\n",
      "  [ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]\n",
      "  [ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]\n",
      "  [ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]]\n",
      "\n",
      " [[ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]\n",
      "  [ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]\n",
      "  [ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]\n",
      "  ...\n",
      "  [ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]\n",
      "  [ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]\n",
      "  [ 0.02873635 -0.24445572 -0.21755669 ...  0.13667998  0.16544306\n",
      "    0.10515153]]], shape=(10, 60, 16), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.shape(char_embeddings)\n",
    "t = tf.transpose(char_embeddings, perm=[1, 0, 2])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([60 10 16], shape=(3,), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(tf.shape(char_embeddings))\n",
    "print(dim_chars)\n",
    "print(dim_words)\n",
    "print(EMBED_DIM_CHAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORD LSTM:S\n",
    "\n",
    "HIDDEN_SIZE=20\n",
    "cell_fw = tf.contrib.rnn.LSTMCell(HIDDEN_SIZE)\n",
    "cell_bw = tf.contrib.rnn.LSTMCell(HIDDEN_SIZE)\n",
    "sequence_length= tf.reshape(x['sentence_length'],[BATCH_SIZE])\n",
    "(output_fw, output_bw), _ = tf.nn.bidirectional_dynamic_rnn(cell_fw,\n",
    "    cell_bw, word_embeddings, sequence_length=sequence_length,\n",
    "    dtype=tf.float32)\n",
    "context_rep = tf.concat([output_fw, output_bw], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5381, shape=(3,), dtype=int32, numpy=array([ 2, 30, 40], dtype=int32)>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(context_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES_OUTPUT=9\n",
    "\n",
    "ntime_steps = tf.shape(context_rep)[1]\n",
    "context_rep_flat = tf.reshape(context_rep, [-1, 2*HIDDEN_SIZE])\n",
    "preds = tf.layers.dense(inputs = context_rep_flat,units=CLASSES_OUTPUT)\n",
    "logits = tf.reshape(preds, [-1, ntime_steps, CLASSES_OUTPUT])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_params = tf.get_variable(\"crf\", [CLASSES_OUTPUT, CLASSES_OUTPUT], dtype=tf.float32)\n",
    "pred_ids, _ = tf.contrib.crf.crf_decode(logits, crf_params, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2971, shape=(2,), dtype=int64, numpy=array([4, 4])>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2971, shape=(2,), dtype=int64, numpy=array([4, 4])>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=13051, shape=(2, 20), dtype=bool, numpy=\n",
       "array([[ True,  True,  True,  True, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False],\n",
       "       [ True,  True,  True,  True, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False]])>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = tf.sequence_mask(sequence_length,maxlen=20)\n",
    "weights\n",
    "#tf.metrics.accuracy(labels, pred_ids, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=10353, shape=(2, 30), dtype=int32, numpy=\n",
       "array([[3, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [3, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=11559, shape=(2, 30), dtype=int64, numpy=\n",
       "array([[2, 8, 8, 0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "        8, 8, 8, 8, 8, 8, 8, 8],\n",
       "       [2, 8, 8, 0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "        8, 8, 8, 8, 8, 8, 8, 8]])>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "labels = tf.reshape(x['labels'],[BATCH_SIZE,SENTENCE_LEN])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=8745, shape=(2, 30, 9), dtype=float32, numpy=\n",
       "array([[[-0.01310119, -0.00056921,  0.00136848,  0.01918247,\n",
       "          0.01797333,  0.00120888, -0.00618167,  0.00519746,\n",
       "          0.0076556 ],\n",
       "        [-0.01320264,  0.0033567 ,  0.0090897 ,  0.02245667,\n",
       "          0.00786415, -0.00058932, -0.0046156 ,  0.00271039,\n",
       "          0.02036974],\n",
       "        [-0.01781182,  0.0007734 ,  0.01562909,  0.01014564,\n",
       "          0.00997417, -0.00045097, -0.00981556,  0.00236148,\n",
       "          0.00493213],\n",
       "        [-0.01214561, -0.00469819,  0.00731217,  0.01789845,\n",
       "          0.00397268,  0.00260659, -0.01979513, -0.0002396 ,\n",
       "          0.00149634],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ]],\n",
       "\n",
       "       [[-0.00438123,  0.00218872,  0.00206503,  0.01834597,\n",
       "         -0.00115548, -0.00814788, -0.00905092,  0.00568968,\n",
       "          0.01721373],\n",
       "        [-0.0052678 ,  0.00432858,  0.00889719,  0.02217122,\n",
       "         -0.00920577, -0.00193623, -0.00757377,  0.00134589,\n",
       "          0.01737449],\n",
       "        [-0.01009628,  0.00126743,  0.01126948,  0.00921324,\n",
       "         -0.01022387,  0.00155813, -0.00985127, -0.00137849,\n",
       "          0.00116658],\n",
       "        [-0.00815152,  0.00291423,  0.00285125,  0.01135802,\n",
       "         -0.02291393,  0.00462494, -0.00491701,  0.00594408,\n",
       "         -0.00396562],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ]]], dtype=float32)>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood, _ = tf.contrib.crf.crf_log_likelihood(\n",
    "        logits, labels, sequence_length, crf_params)\n",
    "loss = tf.reduce_mean(-log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=12710, shape=(), dtype=float32, numpy=9.030251>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOK_UP_TABLE=\"FILE_NAME_TO_LOOP_UP_VOCAB\"\n",
    "\n",
    "if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    # Predictions\n",
    "    # GET THE WORD FORM THE ID, LINK THIS WITH THE BEAM TRANSFORM VOCAB\n",
    "    reverse_vocab_tags = tf.contrib.lookup.index_to_string_table_from_file(\n",
    "        LOOK_UP_TABLE)\n",
    "    pred_strings = reverse_vocab_tags.lookup(tf.to_int64(pred_ids))\n",
    "    predictions = {\n",
    "        'pred_ids': pred_ids,\n",
    "        'tags': pred_strings\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "else:\n",
    "    # Loss\n",
    "    tags = labes\n",
    "    log_likelihood, _ = tf.contrib.crf.crf_log_likelihood(\n",
    "        logits, tags, nwords, crf_params)\n",
    "    loss = tf.reduce_mean(-log_likelihood)\n",
    "\n",
    "    # Metrics\n",
    "    # AWESOME THIS IS GREAT TO USE THIS MASK HERE\n",
    "    # WILL SOLVE A LOT OF PROBLEMS, OTHERWISE\n",
    "    # GOOD LEARNING AS WELL\n",
    "    weights = tf.sequence_mask(nwords)\n",
    "    metrics = {\n",
    "        'acc': tf.metrics.accuracy(tags, pred_ids, weights),\n",
    "        'precision': precision(tags, pred_ids, num_tags, indices, weights),\n",
    "        'recall': recall(tags, pred_ids, num_tags, indices, weights),\n",
    "        'f1': f1(tags, pred_ids, num_tags, indices, weights),\n",
    "    }\n",
    "    # ADD THEM ALL TO THE GRAPH\n",
    "    for metric_name, op in metrics.items():\n",
    "        tf.summary.scalar(metric_name, op[1])\n",
    "    \n",
    "    # WHAT WILL HAPPEN IF WE HAVE EVAL MODE\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode, loss=loss, eval_metric_ops=metrics)\n",
    "\n",
    "    # WHAT WILL HAPPEN IF WE HAVE TRAIN? \n",
    "    elif mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        train_op = tf.train.AdamOptimizer().minimize(\n",
    "            loss, global_step=tf.train.get_or_create_global_step())\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=13026, shape=(), dtype=int32, numpy=9>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = 9\n",
    "NUM_CLASSES = tf.constant(NUM_CLASSES)\n",
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
