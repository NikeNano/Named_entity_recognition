{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow_transform.tf_metadata import dataset_metadata, metadata_io,dataset_schema \n",
    "from tensorflow_transform.beam.tft_beam_io import transform_fn_io\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Niklas/Documents/Named_entity_recognition/model/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAVE TO RE RUN ALL! AND CLEAR FOLDERS\n",
    "\n",
    "https://guillaumegenthial.github.io/sequence-tagging-with-tensorflow.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_metadata = metadata_io.read_metadata(\n",
    "    os.path.join(\n",
    "      \"gs://named_entity_recognition/beam/\", transform_fn_io.TRANSFORMED_METADATA_DIR\n",
    "      )\n",
    "    )\n",
    "transformed_feature_spec = transformed_metadata.schema.as_feature_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'chars': FixedLenFeature(shape=[30, 10], dtype=tf.int64, default_value=None),\n",
       " u'chars_in_word': FixedLenFeature(shape=[30], dtype=tf.int64, default_value=None),\n",
       " u'id': FixedLenFeature(shape=[], dtype=tf.float32, default_value=None),\n",
       " u'label': FixedLenFeature(shape=[], dtype=tf.string, default_value=None),\n",
       " u'label_length': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None),\n",
       " u'labels': FixedLenFeature(shape=[30], dtype=tf.int64, default_value=None),\n",
       " u'sentence_length': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None),\n",
       " u'text': FixedLenFeature(shape=[], dtype=tf.string, default_value=None),\n",
       " u'word_representation': VarLenFeature(dtype=tf.int64)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_feature_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_from_tfrecord(example_proto):\n",
    "    features = tf.parse_example([example_proto], features=transformed_feature_spec)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.TFRecordDataset(\"gs://named_entity_recognition/beam/TEST-00000-of-00005\").map(_read_from_tfrecord).batch(2).make_one_shot_iterator()\n",
    "for x in ds:\n",
    "    output_list.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[9]\n",
      " [3]], shape=(2, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[['CRICKET - ENGLAND V PAKISTAN FINAL TEST SCOREBOARD .']\n",
      " ['BUENOS AIRES 1996-08-26']], shape=(2, 1), dtype=string)\n",
      "tf.Tensor(\n",
      "[[6]\n",
      " [4]], shape=(2, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[['Fastest lap : Aoki 147.786 kph']\n",
      " ['-- Chicago newsdesk 312-408-8787']], shape=(2, 1), dtype=string)\n",
      "tf.Tensor(\n",
      "[[35]\n",
      " [ 9]], shape=(2, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[['Most including former president F.W. de Klerk and African National Congress Deputy President Thabo Mbeki offered apologies for any mistakes they had made and accepted broad responsibility for the actions of their foot soldiers .']\n",
      " ['No1 Bare Bright 91 to 92 cents / pound']], shape=(2, 1), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for x in output_list:\n",
    "    print(x[\"sentence_length\"])\n",
    "    print(x[\"text\"])\n",
    "    count=count +1\n",
    "    if count>2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_lowercase\n",
    "MAPPING = {a:index for index,a in enumerate(ascii_lowercase + ascii_lowercase.upper())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruit = 'Apple'\n",
    "isApple = True if fruit == 'Apple' else False\n",
    "\n",
    "a = 3\n",
    "b = a if a<5 else 5\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'word_representation',\n",
       " u'text',\n",
       " u'chars',\n",
       " u'labels',\n",
       " u'label',\n",
       " u'label_length',\n",
       " u'sentence_length',\n",
       " u'id',\n",
       " u'chars_in_word']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]]\n",
      "\n",
      " [[8 8 6 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]]], shape=(2, 1, 30), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[15]\n",
      " [19]], shape=(2, 1), dtype=int64)\n",
      "tf.Tensor([15 19], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(x['labels'])\n",
    "print(x['sentence_length'])\n",
    "print(tf.reshape(x['sentence_length'],[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['I got the good part of the bat on it and it carried out .'],\n",
       "       ['The 36-year-old Briton is still considering the offer and is expected to announce his decision later on Wednesday .']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = x[\"text\"].numpy()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[15]\n",
      " [19]], shape=(2, 1), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(x['sentence_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCE_LEN=30\n",
    "WORD_LEN=10\n",
    "BATCH_SIZE=2\n",
    "CHAR_SIZE=54\n",
    "EMBED_DIM_CHAR=int(CHAR_SIZE**(1/4))*8\n",
    "DEFAULT_WORD_VALUE =0\n",
    "VOCAB_SIZE=1e4\n",
    "EMBED_DIM_WORD=int(VOCAB_SIZE**(1/4))*8\n",
    "input_char = tf.reshape(x[\"chars\"],[BATCH_SIZE,SENTENCE_LEN,WORD_LEN])\n",
    "char_embedding = tf.contrib.layers.embed_sequence(\n",
    "    input_char, vocab_size=CHAR_SIZE, embed_dim=EMBED_DIM_CHAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-bb5840865123>:3: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n"
     ]
    }
   ],
   "source": [
    "# No padding needed now :) \n",
    "input_word = tf.sparse_to_dense(x[\"word_representation\"].indices,[BATCH_SIZE,1,SENTENCE_LEN],\n",
    "                           x[\"word_representation\"].values,default_value=DEFAULT_WORD_VALUE\n",
    "                          )\n",
    "input_word = tf.reshape(input_word,[BATCH_SIZE,SENTENCE_LEN])\n",
    "word_embedding = tf.contrib.layers.embed_sequence(\n",
    "    input_word, vocab_size=VOCAB_SIZE, embed_dim=EMBED_DIM_WORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=86, shape=(2, 1, 30), dtype=int64, numpy=\n",
       "array([[[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "         8, 8, 8, 8, 8, 8, 8, 8, 8]],\n",
       "\n",
       "       [[8, 8, 6, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "         8, 8, 8, 8, 8, 8, 8, 8, 8]]])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=86, shape=(2, 1, 30), dtype=int64, numpy=\n",
       "array([[[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "         8, 8, 8, 8, 8, 8, 8, 8, 8]],\n",
       "\n",
       "       [[8, 8, 6, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "         8, 8, 8, 8, 8, 8, 8, 8, 8]]])>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=29845, shape=(2, 30), dtype=int64, numpy=\n",
       "array([[  59,  803,    1,  392,  260,    2,    1, 1622,    9,   33,    8,\n",
       "          33, 2613,   64,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [  15,    0, 4812,   26,  239, 2346,    1, 1012,    8,   26,  176,\n",
       "           4, 2370,   34,  534,  492,    9,   71,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0]])>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 2 30], shape=(2,), dtype=int32)\n",
      "tf.Tensor([ 2 30 80], shape=(3,), dtype=int32)\n",
      "tf.Tensor([ 2 30 10 16], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes \n",
    "print(tf.shape(input_word))\n",
    "print(tf.shape(word_embedding))\n",
    "print(tf.shape(char_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.shape(char_embedding)\n",
    "char_embeddings = tf.reshape(char_embedding, shape=[-1, s[-2], s[-1]])\n",
    "word_lengths = tf.reshape(x['chars_in_word'],[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_HIDDEN_SIZE=10\n",
    "# 3. bi lstm on chars\n",
    "cell_fw = tf.contrib.rnn.LSTMCell(CHAR_HIDDEN_SIZE, state_is_tuple=True)\n",
    "cell_bw = tf.contrib.rnn.LSTMCell(CHAR_HIDDEN_SIZE, state_is_tuple=True)\n",
    "\n",
    "_, ((_, output_fw), (_, output_bw)) = tf.nn.bidirectional_dynamic_rnn(cell_fw,\n",
    "    cell_bw, char_embeddings, sequence_length=word_lengths,\n",
    "    dtype=tf.float32)\n",
    "#shape = (batch x sentence, 2 x char_hidden_size)\n",
    "output = tf.concat([output_fw, output_bw], axis=-1)\n",
    "\n",
    "# shape = (batch, sentence, 2 x char_hidden_size)\n",
    "char_rep = tf.reshape(output, shape=[-1, s[1], 2*CHAR_HIDDEN_SIZE])\n",
    "\n",
    "# shape = (batch, sentence, 2 x char_hidden_size + word_vector_size)\n",
    "word_embeddings = tf.concat([word_embedding, char_rep], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=29883, shape=(60,), dtype=int64, numpy=\n",
       "array([ 1,  3,  3,  4,  4,  2,  3,  3,  2,  2,  3,  2,  7,  3,  1,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  3, 10,  6,  2,\n",
       "        5, 10,  3,  5,  3,  2,  8,  2,  8,  3,  8,  5,  2,  9,  1,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_words = tf.shape(char_embeddings)[1]\n",
    "dim_chars = tf.shape(char_embeddings)[2]\n",
    "flat = tf.reshape(char_embeddings, [-1, dim_words,EMBED_DIM_CHAR])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]\n",
      "  [ 0.29159194 -0.22921945 -0.25485438 ...  0.14288145  0.2496165\n",
      "   -0.10974234]\n",
      "  [ 0.2593913  -0.24994501 -0.00471407 ...  0.19682276 -0.271191\n",
      "   -0.17006284]\n",
      "  ...\n",
      "  [-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]\n",
      "  [-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]\n",
      "  [-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]]\n",
      "\n",
      " [[-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]\n",
      "  [-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]\n",
      "  [ 0.23106164 -0.02746925 -0.13947603 ...  0.22402978  0.12154296\n",
      "   -0.27353936]\n",
      "  ...\n",
      "  [-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]\n",
      "  [-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]\n",
      "  [-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]]\n",
      "\n",
      " [[-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]\n",
      "  [-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]\n",
      "  [ 0.21825826  0.13139534  0.00999457 ...  0.22730851 -0.175349\n",
      "    0.23842514]\n",
      "  ...\n",
      "  [-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]\n",
      "  [-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]\n",
      "  [-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]\n",
      "  [-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]\n",
      "  [-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]\n",
      "  ...\n",
      "  [-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]\n",
      "  [-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]\n",
      "  [-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]]\n",
      "\n",
      " [[-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]\n",
      "  [-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]\n",
      "  [-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]\n",
      "  ...\n",
      "  [-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]\n",
      "  [-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]\n",
      "  [-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]]\n",
      "\n",
      " [[-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]\n",
      "  [-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]\n",
      "  [-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]\n",
      "  ...\n",
      "  [-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]\n",
      "  [-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]\n",
      "  [-0.276442    0.09469041 -0.24847177 ...  0.23459393 -0.0731729\n",
      "    0.15602005]]], shape=(10, 60, 16), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.shape(char_embeddings)\n",
    "t = tf.transpose(char_embeddings, perm=[1, 0, 2])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([60 10 16], shape=(3,), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(tf.shape(char_embeddings))\n",
    "print(dim_chars)\n",
    "print(dim_words)\n",
    "print(EMBED_DIM_CHAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORD LSTM:S\n",
    "\n",
    "HIDDEN_SIZE=20\n",
    "cell_fw = tf.contrib.rnn.LSTMCell(HIDDEN_SIZE)\n",
    "cell_bw = tf.contrib.rnn.LSTMCell(HIDDEN_SIZE)\n",
    "sequence_length= tf.reshape(x['sentence_length'],[BATCH_SIZE])\n",
    "(output_fw, output_bw), _ = tf.nn.bidirectional_dynamic_rnn(cell_fw,\n",
    "    cell_bw, word_embeddings, sequence_length=sequence_length,\n",
    "    dtype=tf.float32)\n",
    "context_rep = tf.concat([output_fw, output_bw], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=30916, shape=(2,), dtype=int64, numpy=array([15, 19])>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=30891, shape=(2, 30, 100), dtype=float32, numpy=\n",
       "array([[[-0.01792703, -0.00522212,  0.01281289, ...,  0.02264906,\n",
       "          0.00806679, -0.06072659],\n",
       "        [ 0.00194441, -0.01352117,  0.02402751, ...,  0.05622904,\n",
       "          0.00528315, -0.07553377],\n",
       "        [ 0.01745144,  0.02065966, -0.01256571, ..., -0.03619995,\n",
       "         -0.01457127,  0.04420982],\n",
       "        ...,\n",
       "        [ 0.01814665, -0.00356887,  0.00626756, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.01814665, -0.00356887,  0.00626756, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.01814665, -0.00356887,  0.00626756, ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.00730885, -0.001112  , -0.01668721, ...,  0.05332617,\n",
       "          0.03637786, -0.12949157],\n",
       "        [ 0.01814665, -0.00356887,  0.00626756, ...,  0.0767253 ,\n",
       "          0.07335322, -0.04356287],\n",
       "        [-0.01765737,  0.02409077, -0.00847279, ..., -0.00430214,\n",
       "          0.08887688, -0.05714823],\n",
       "        ...,\n",
       "        [ 0.01814665, -0.00356887,  0.00626756, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.01814665, -0.00356887,  0.00626756, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.01814665, -0.00356887,  0.00626756, ...,  0.        ,\n",
       "          0.        ,  0.        ]]], dtype=float32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 19])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(sequence_length)\n",
    "sequence_length.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=36699, shape=(3,), dtype=int32, numpy=array([  2,  30, 100], dtype=int32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=36701, shape=(3,), dtype=int32, numpy=array([ 2, 30, 40], dtype=int32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(context_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES_OUTPUT=9\n",
    "\n",
    "ntime_steps = tf.shape(context_rep)[1]\n",
    "context_rep_flat = tf.reshape(context_rep, [-1, 2*HIDDEN_SIZE])\n",
    "preds = tf.layers.dense(inputs = context_rep_flat,units=CLASSES_OUTPUT)\n",
    "logits = tf.reshape(preds, [-1, ntime_steps, CLASSES_OUTPUT])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_params = tf.get_variable(\"crf\", [CLASSES_OUTPUT, CLASSES_OUTPUT], dtype=tf.float32)\n",
    "pred_ids, _ = tf.contrib.crf.crf_decode(logits, crf_params, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=30916, shape=(2,), dtype=int64, numpy=array([15, 19])>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=30916, shape=(2,), dtype=int64, numpy=array([15, 19])>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=35453, shape=(2, 20), dtype=bool, numpy=\n",
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False, False, False,\n",
       "        False, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False]])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = tf.sequence_mask(sequence_length,maxlen=20)\n",
    "weights\n",
    "#tf.metrics.accuracy(labels, pred_ids, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=35441, shape=(2, 30), dtype=int32, numpy=\n",
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=35457, shape=(2, 30), dtype=int64, numpy=\n",
       "array([[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "        8, 8, 8, 8, 8, 8, 8, 8],\n",
       "       [8, 8, 6, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "        8, 8, 8, 8, 8, 8, 8, 8]])>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "labels = tf.reshape(x['labels'],[BATCH_SIZE,SENTENCE_LEN])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=33635, shape=(2, 30, 9), dtype=float32, numpy=\n",
       "array([[[ 1.00542437e-02, -5.97223081e-03,  2.55422899e-03,\n",
       "          1.58257037e-02,  2.99501233e-03, -1.23573449e-02,\n",
       "          1.14818653e-02, -1.48824723e-02,  1.87883638e-02],\n",
       "        [ 1.41725074e-02, -2.30121613e-03,  5.74503094e-03,\n",
       "          1.55944154e-02,  1.78433256e-04, -8.53263028e-03,\n",
       "          1.14082890e-02, -1.93446446e-02,  1.97767559e-02],\n",
       "        [ 2.16319989e-02,  7.90296588e-04,  1.70470439e-02,\n",
       "          1.85925495e-02, -1.06485840e-02, -1.27577577e-02,\n",
       "          5.96372504e-03, -1.14536602e-02,  5.58378175e-03],\n",
       "        [ 1.23999678e-02, -3.46580031e-03,  7.40117300e-03,\n",
       "          1.20074339e-02, -8.95404816e-03, -3.34595423e-03,\n",
       "          8.69130343e-03, -7.45484699e-03,  4.09019180e-03],\n",
       "        [ 1.67719908e-02,  1.93982502e-03,  1.98841188e-02,\n",
       "          1.72285754e-02, -2.10856088e-02,  7.34140538e-03,\n",
       "          3.26080993e-03, -7.19738146e-03,  8.64688307e-04],\n",
       "        [ 1.44431170e-03, -1.68674241e-03,  3.95822478e-03,\n",
       "          1.08760912e-02, -1.70538388e-02,  1.05460053e-02,\n",
       "          5.19108586e-03, -8.33881181e-03,  1.41032750e-03],\n",
       "        [ 5.32065146e-03,  2.73945369e-03,  1.38015742e-03,\n",
       "          1.68028567e-02, -1.43731097e-02,  5.11342380e-03,\n",
       "          2.37494498e-03, -1.75374281e-02,  4.27240552e-03],\n",
       "        [ 7.90331420e-03, -3.22110718e-04, -9.36690345e-03,\n",
       "          1.59729291e-02, -5.43274311e-03, -1.90042169e-03,\n",
       "         -2.49001896e-03,  2.54991231e-04, -7.26465043e-03],\n",
       "        [ 3.36612575e-04, -2.40381621e-03, -6.52429275e-03,\n",
       "          1.47446813e-02, -8.55517667e-03, -2.08011293e-03,\n",
       "         -9.16973036e-03,  9.60919168e-03, -1.08389463e-02],\n",
       "        [ 7.70161580e-03, -5.26745804e-04, -2.50009354e-03,\n",
       "          1.78754311e-02, -5.21955453e-03,  5.03617525e-03,\n",
       "         -1.64784752e-02,  6.77591749e-03, -1.00370329e-02],\n",
       "        [ 1.54563133e-03, -7.50990864e-03, -8.97959061e-03,\n",
       "          6.56835968e-03, -4.38737264e-03,  1.28155062e-03,\n",
       "         -1.01458654e-02,  1.50288297e-02, -7.19929812e-03],\n",
       "        [-2.10254476e-03, -9.33683664e-03, -7.47427950e-03,\n",
       "          7.06777396e-03,  2.79531488e-03, -8.98649450e-05,\n",
       "         -1.11032603e-02,  1.55370580e-02, -1.03598665e-02],\n",
       "        [-1.66555040e-03, -3.19309067e-03,  2.98032071e-03,\n",
       "          7.08523300e-03, -5.85085806e-03, -3.55555094e-04,\n",
       "         -8.00708833e-04,  4.53836704e-03, -1.20413974e-02],\n",
       "        [ 8.27080384e-03,  1.10644894e-02,  1.22831678e-02,\n",
       "          1.02219020e-03,  5.75017743e-03,  1.14221442e-02,\n",
       "          4.12748381e-03,  2.52555124e-03, -1.03933644e-02],\n",
       "        [ 6.15228899e-03,  5.24754729e-03,  1.85979847e-02,\n",
       "          1.08231474e-02,  1.28544203e-03,  1.18241571e-02,\n",
       "          1.03188585e-03,  7.92005192e-03, -1.49184475e-02],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       "\n",
       "       [[ 2.15187063e-03, -9.16266628e-03, -2.50565838e-02,\n",
       "         -5.12939226e-03, -5.71052078e-03, -3.73029779e-03,\n",
       "         -4.48203832e-03, -4.59520519e-03,  5.63666224e-03],\n",
       "        [-2.65938789e-03, -1.35893961e-02, -1.41248293e-02,\n",
       "         -3.59434844e-03, -1.25131607e-02,  5.26503846e-03,\n",
       "          6.14103675e-03, -6.54457929e-03, -3.54025979e-03],\n",
       "        [-5.20997075e-03, -3.86717007e-03, -1.51890302e-02,\n",
       "         -5.35114156e-03,  1.86122339e-02, -1.68866962e-02,\n",
       "          1.44751193e-02, -6.91116974e-03, -1.53114344e-03],\n",
       "        [ 8.70903721e-04, -3.74328741e-03, -1.39957778e-02,\n",
       "         -3.48241883e-04,  8.59075785e-03, -1.64734460e-02,\n",
       "          1.68218103e-04, -1.22198705e-02,  3.74202058e-03],\n",
       "        [ 2.60189548e-03, -1.14167612e-02, -1.68138780e-02,\n",
       "          9.12649557e-03, -8.90486408e-04, -1.60264820e-02,\n",
       "         -4.28609084e-03, -4.68462566e-03, -5.44848293e-03],\n",
       "        [ 4.50259307e-04, -1.03537077e-02,  5.86948730e-03,\n",
       "          1.14389900e-02, -6.64858613e-03, -1.42752845e-02,\n",
       "          9.64263454e-04, -5.79202268e-03, -1.15123512e-02],\n",
       "        [ 1.03243475e-03,  5.10841259e-04,  1.10761924e-02,\n",
       "          1.18103605e-02, -5.98576479e-03, -9.14805662e-03,\n",
       "          3.24745616e-03, -1.49988644e-02, -1.06260926e-02],\n",
       "        [-1.40629327e-02, -9.92937386e-03, -7.39714690e-03,\n",
       "          1.15871066e-02, -3.46273952e-03, -6.49568345e-03,\n",
       "          3.22064105e-03, -1.07205734e-02, -1.07470891e-02],\n",
       "        [-1.73032023e-02, -6.27603102e-03, -1.22924577e-02,\n",
       "          4.27860441e-03, -1.46240694e-03, -1.73074892e-03,\n",
       "         -3.61453305e-04, -7.63924420e-03, -3.96252982e-03],\n",
       "        [-1.24063138e-02, -1.39294891e-02, -1.84467956e-02,\n",
       "          9.44516622e-03,  4.42066463e-04, -1.82972439e-02,\n",
       "         -1.70559566e-02,  6.76150760e-03, -1.43694086e-02],\n",
       "        [-9.95152723e-03, -2.06181761e-02, -1.88370906e-02,\n",
       "          1.62722655e-02, -1.15260035e-02, -1.57687161e-02,\n",
       "         -1.69032067e-02,  3.32932151e-03, -1.41253406e-02],\n",
       "        [ 5.51964203e-03, -7.27515435e-03, -8.59718397e-03,\n",
       "          1.71308983e-02, -1.24974400e-02, -1.95501861e-03,\n",
       "         -1.26060061e-02, -2.47488683e-03, -7.74934608e-03],\n",
       "        [ 8.66738707e-03, -1.30654257e-02, -1.62833165e-02,\n",
       "          1.94423050e-02, -1.89811848e-02,  1.54773414e-03,\n",
       "         -2.54218373e-03, -2.25691241e-03, -1.20029449e-02],\n",
       "        [-1.13380784e-02, -2.45844666e-03, -1.45095224e-02,\n",
       "          1.23917516e-02,  3.37490859e-03, -2.24142298e-02,\n",
       "         -2.65812408e-03,  2.87138135e-03, -2.26901267e-02],\n",
       "        [-1.50712230e-03, -4.92127612e-03, -8.77798162e-03,\n",
       "          1.56488977e-02, -2.94061750e-03, -1.59683339e-02,\n",
       "          3.30479699e-04, -3.25789908e-03, -2.04508249e-02],\n",
       "        [ 6.55109249e-03, -3.81321134e-03,  2.57984363e-03,\n",
       "          1.64299197e-02, -8.26504454e-03, -1.30558535e-02,\n",
       "         -9.02714301e-03,  7.34998984e-03, -1.86721813e-02],\n",
       "        [-3.86737799e-03, -7.43132085e-03, -1.12918718e-03,\n",
       "          1.13904336e-02, -1.25807822e-02, -2.67142896e-03,\n",
       "         -5.19696297e-03,  1.24842655e-02, -2.14408953e-02],\n",
       "        [ 9.12389439e-03, -1.34108542e-02, -4.97809239e-03,\n",
       "          1.57395285e-02, -2.41407435e-02,  2.52164900e-04,\n",
       "         -5.30646369e-03,  6.62679551e-03, -2.01864745e-02],\n",
       "        [-2.22220644e-03,  8.08368262e-04,  1.19393114e-02,\n",
       "          6.99579529e-03, -8.59537069e-03,  8.11006781e-03,\n",
       "          7.58354831e-03,  1.28529472e-02, -2.64059547e-02],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood, _ = tf.contrib.crf.crf_log_likelihood(\n",
    "        logits, labels, sequence_length, crf_params)\n",
    "loss = tf.reduce_mean(-log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=36686, shape=(), dtype=float32, numpy=45.423134>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOK_UP_TABLE=\"FILE_NAME_TO_LOOP_UP_VOCAB\"\n",
    "\n",
    "if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    # Predictions\n",
    "    # GET THE WORD FORM THE ID, LINK THIS WITH THE BEAM TRANSFORM VOCAB\n",
    "    reverse_vocab_tags = tf.contrib.lookup.index_to_string_table_from_file(\n",
    "        LOOK_UP_TABLE)\n",
    "    pred_strings = reverse_vocab_tags.lookup(tf.to_int64(pred_ids))\n",
    "    predictions = {\n",
    "        'pred_ids': pred_ids,\n",
    "        'tags': pred_strings\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "else:\n",
    "    # Loss\n",
    "    tags = labes\n",
    "    log_likelihood, _ = tf.contrib.crf.crf_log_likelihood(\n",
    "        logits, tags, nwords, crf_params)\n",
    "    loss = tf.reduce_mean(-log_likelihood)\n",
    "\n",
    "    # Metrics\n",
    "    # AWESOME THIS IS GREAT TO USE THIS MASK HERE\n",
    "    # WILL SOLVE A LOT OF PROBLEMS, OTHERWISE\n",
    "    # GOOD LEARNING AS WELL\n",
    "    weights = tf.sequence_mask(nwords)\n",
    "    metrics = {\n",
    "        'acc': tf.metrics.accuracy(tags, pred_ids, weights),\n",
    "        'precision': precision(tags, pred_ids, num_tags, indices, weights),\n",
    "        'recall': recall(tags, pred_ids, num_tags, indices, weights),\n",
    "        'f1': f1(tags, pred_ids, num_tags, indices, weights),\n",
    "    }\n",
    "    # ADD THEM ALL TO THE GRAPH\n",
    "    for metric_name, op in metrics.items():\n",
    "        tf.summary.scalar(metric_name, op[1])\n",
    "    \n",
    "    # WHAT WILL HAPPEN IF WE HAVE EVAL MODE\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode, loss=loss, eval_metric_ops=metrics)\n",
    "\n",
    "    # WHAT WILL HAPPEN IF WE HAVE TRAIN? \n",
    "    elif mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        train_op = tf.train.AdamOptimizer().minimize(\n",
    "            loss, global_step=tf.train.get_or_create_global_step())\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 9\n",
    "NUM_CLASSES = tf.constant(NUM_CLASSES)\n",
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
